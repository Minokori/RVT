{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from utils import train_transform,val_transform,imagedataloader\n",
    "from utils import train_transform, imagedataloader\n",
    "from RetNet import *\n",
    "from train_retnet import Trainer\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from Nets import visiontransformer, altgvt, mobilenetv3\n",
    "testname = \"statefarmMB_1_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileV3配置和GVT相同\n",
    "\n",
    "1_1 ,2.0G - 0.8G 67min\n",
    "\n",
    "1_2,2.4G -0.8G 67min\n",
    "\n",
    "1_3 2.0G -0.8G\n",
    "1_4 256min 2.4-0.8G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTGVT 配置见config Batchsize = 128, 显存2.2-0.8=1.410步1e-3准确率89%, 12min\n",
    "\n",
    "GVT1_1 3.3-0.8G, B256, EP50[5,15,30],61min\n",
    "\n",
    "GVT1_2 5.3-0.8G, B512, EP50[5,15,30],63min\n",
    "\n",
    "GVT1_3 3.2-0.8G, B256 EP200[20,50,100,150], 246min\n",
    "\n",
    "GVT1_4 3.2-0.8G, B256 EP200[20,50,100,150], 246min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statefarmMSR4_1 B = 256, 157min,100epoch\n",
    "# 5_1,bs=64,imgs=256,50[5,15,30],317min\n",
    "# 6_1,bs=256,预处理和原论文一样(变简单了),imgs=64\n",
    "# 7-1\n",
    "def main():\n",
    "\n",
    "    # Training parameters\n",
    "    split = (0.7, 0.3)\n",
    "    batch_size = 512  # 在256测试了16, 32, 64, 128， 64最快(有chunk)\n",
    "    epochs = 50\n",
    "    lr = 1e-3\n",
    "    device = torch.device(\"cuda\")\n",
    "    save_model_every_n_epochs = 20\n",
    "    trainloader, valloader, _ = imagedataloader(split=split,\n",
    "                                                path=\"./data/statefarm/\", batchsize=batch_size, transform=train_transform,\n",
    "                                                )\n",
    "    # Create the model, optimizer, loss function and trainer\n",
    "    # [ ]\n",
    "    # model = visiontransformer.to(device)\n",
    "    # [ ]\n",
    "    # model = altgvt.to(device)\n",
    "    # [ ]\n",
    "    # model = mobilenetv3.to(device)\n",
    "    model = ImageRetResNet(device=device).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15, 30], gamma=0.1)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    trainer = Trainer(model, optimizer, loss_fn, testname, device=device, scheduler=scheduler)\n",
    "    trainer.train(trainloader, valloader, epochs, save_model_every_n_epochs=save_model_every_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "testname = \"statefarmMSR6_1\"\n",
    "metrics_file = os.path.join(f\"./experiments/{testname}/\", 'metrics.json')\n",
    "with open(metrics_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    train_losses = data['train_losses']\n",
    "    test_losses = data['test_losses']\n",
    "    accuracies = data['accuracies']\n",
    "\n",
    "# Create two subplots of train/test losses and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(train_losses, label=\"Train loss\")\n",
    "ax1.plot(test_losses, label=\"Val loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "ax2.plot(accuracies)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "plt.savefig(f\"{testname}.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchstat import stat\n",
    "# model = altgvt\n",
    "# stat(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randn(3, 64, 64)\n",
    "# a = a.unsqueeze(0)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3,64,64**\n",
    "\n",
    "Total params: 1,253,446\n",
    "Total memory: 1.06MB\n",
    "Total MAdd: 19.98MMAdd\n",
    "Total Flops: 10.1MFlops\n",
    "Total MemR+W: 6.48MB\n",
    "\n",
    "---\n",
    "\n",
    "**3,256,256**\n",
    "\n",
    "Total params: 1,253,446\n",
    "Total memory: 16.91MB\n",
    "Total MAdd: 319.47MMAdd\n",
    "Total Flops: 161.44MFlops\n",
    "Total MemR+W: 32.03MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = visiontransformer\n",
    "summary(model, input_size=(3, 64, 64), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total params: 1,256,326\n",
    "Trainable params: 1,256,326\n",
    "Non-trainable params: 0\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 2.63\n",
    "Params size (MB): 4.79\n",
    "Estimated Total Size (MB): 7.47"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
